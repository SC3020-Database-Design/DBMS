{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /usr/local/anaconda3/lib/python3.9/site-packages (2.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import logging\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global conn\n",
    "try:\n",
    "  conn = psycopg2.connect(\n",
    "      dbname=\"tpc\",\n",
    "      user=\"postgres\",\n",
    "      password=\"password\",\n",
    "      host=\"localhost\",\n",
    "      port=\"5432\"\n",
    "  )\n",
    "  logging.info(\"Database connection established.\")\n",
    "except Exception as e:\n",
    "  print(f\"An error occurred while connecting to the database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "REFRESH_STATS_QUERY = \"\"\"\n",
    "DO $$\n",
    "DECLARE\n",
    "    table_name TEXT;\n",
    "BEGIN\n",
    "    FOR table_name IN\n",
    "        SELECT tablename\n",
    "        FROM pg_catalog.pg_tables\n",
    "        WHERE schemaname = 'public' -- Specify the schema if needed\n",
    "    LOOP\n",
    "        EXECUTE format('ANALYZE %I', table_name);\n",
    "    END LOOP;\n",
    "END $$;\n",
    "\"\"\"\n",
    "\n",
    "RELATION_PROPERTIES_QUERY = \"\"\"\n",
    "SELECT relname, reltuples, relpages \n",
    "FROM pg_class \n",
    "WHERE relkind IN ('r');\n",
    "\"\"\"\n",
    "\n",
    "SETTINGS_QUERY = \"\"\"\n",
    "SELECT relname, current_setting('random_page_cost')::real,current_setting('cpu_index_tuple_cost')::real, current_setting('cpu_operator_cost')::real, current_setting('cpu_tuple_cost')::real, current_setting('seq_page_cost')::real, relpages AS pages, reltuples AS tuples\n",
    "from pg_class;\n",
    "\"\"\"\n",
    "\n",
    "class Explainer:\n",
    "    tableSet = {'lineitem', 'orders','customer','partsupp','supplier','part','nation','region'}\n",
    "    properties = defaultdict(lambda: {})\n",
    "\n",
    "    def __init__(self, conn):\n",
    "        self.conn = conn\n",
    "        self.run(REFRESH_STATS_QUERY)\n",
    "\n",
    "        result = self.run(SETTINGS_QUERY)\n",
    "        for relname, random_page_cost, cpu_index_tuple_cost, cpu_operator_cost, cpu_tuple_cost, seq_page_cost, pages, tuples in result:\n",
    "            if relname.split('_')[0] in self.tableSet:\n",
    "                self.properties[relname]['pages'] = pages\n",
    "                self.properties[relname]['tuples'] = tuples\n",
    "                self.properties['random_page_cost'] = random_page_cost\n",
    "                self.properties['cpu_index_tuple_cost'] = cpu_index_tuple_cost\n",
    "                self.properties['cpu_operator_cost'] = cpu_operator_cost\n",
    "                self.properties['cpu_tuple_cost'] = cpu_tuple_cost\n",
    "                self.properties['seq_page_cost'] = seq_page_cost\n",
    "\n",
    "        self.cost_estimator = CostEstimator(self.properties)\n",
    "\n",
    "    def run(self, query):\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(query)\n",
    "        try:\n",
    "            return cur.fetchall()\n",
    "        except:\n",
    "            logging.warning(\"No rows fetched; Returning []\")\n",
    "            return []\n",
    "\n",
    "    def run_explain(self, query):\n",
    "        \"\"\"\n",
    "        Executes the EXPLAIN command on a given SQL query using a PostgreSQL connection\n",
    "        and returns the JSON-formatted plan.\n",
    "\n",
    "        See 'EXPLAIN' documentation:\n",
    "        https://www.postgresql.org/docs/current/sql-explain.html\n",
    "\n",
    "        See psycopg2 documentation:\n",
    "        https://www.psycopg.org/docs/cursor.html#cursor.execute\n",
    "\n",
    "        Parameters:\n",
    "        query (str): SQL query to be explained.\n",
    "        conn (psycopg2.connection): Active database connection object.\n",
    "\n",
    "        Returns:\n",
    "        list: A list of dictionaries representing the JSON formatted execution plan returned by PostgreSQL.\n",
    "        \"\"\"\n",
    "        with self.conn.cursor() as cur:\n",
    "            # cur.execute(f\"EXPLAIN (ANALYZE true, BUFFERS true, FORMAT json) {query}\")\n",
    "            cur.execute(f\"EXPLAIN (ANALYZE true, FORMAT json) {query}\")\n",
    "            explain_output = cur.fetchone()[0]\n",
    "            logging.info(\"EXPLAIN command executed successfully.\")\n",
    "            # psycopg2 implicitly converts the JSON output to a list of dictionaries (python)\n",
    "            return explain_output\n",
    "\n",
    "    def analyze_node(self, node):\n",
    "        \"\"\"\n",
    "        Analyze a single node within the execution plan, extracting estimated cost metrics from the PostgreSQL planner\n",
    "        ,  and recursively processing any sub-plans.\n",
    "\n",
    "        Parameters:\n",
    "        node (dict): A single node from the JSON execution plan.\n",
    "\n",
    "        Returns:\n",
    "        dict: Node and sub-nodes analysis including both estimated and computed costs.\n",
    "        \"\"\"\n",
    "        # Extract estimated cost metrics provided by PostgreSQL\n",
    "        plan_properties = self.get_plan_properties(node)\n",
    "        estimated_cost, explanation = self.cost_estimator.estimate(node)\n",
    "\n",
    "        # Create a dictionary for this node's analysis that includes both sets of cost metrics\n",
    "        node_analysis = {\n",
    "            'Node Type': node.get('Node Type'),\n",
    "            'Relation Name': node.get('Relation Name', 'N/A'),\n",
    "            'Cost Analysis': {\n",
    "                'Actual Estimated Cost': node.get('Total Cost'),\n",
    "                'Estimated Cost': estimated_cost,\n",
    "                'Explanation': explanation\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Recursively analyze any sub-plans and include their analysis\n",
    "        if 'Plans' in node:\n",
    "            sub_plans = [self.analyze_node(sub_node) for sub_node in node['Plans']]\n",
    "            node_analysis['Sub-plans'] = sub_plans\n",
    "\n",
    "        return node_analysis\n",
    "\n",
    "\n",
    "    def analyze_execution_plan(self, explain_output):\n",
    "        \"\"\"\n",
    "        Initiates the recursive analysis of the entire execution plan from the top-level node.\n",
    "\n",
    "        Parameters:\n",
    "        explain_output (list): The JSON execution plan as a list from PostgreSQL.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary representing the analyzed execution plan including nested sub-plans.\n",
    "        \"\"\"\n",
    "        if explain_output:\n",
    "            # The execution plan is enclosed in a list -> start with the first item\n",
    "            return self.analyze_node(explain_output[0]['Plan'])\n",
    "        else:\n",
    "            logging.error(\"No execution plan found.\")\n",
    "            return {}\n",
    "\n",
    "\n",
    "    def get_plan_properties(self, node):\n",
    "        \"\"\"\n",
    "        Utility function to extract cost-related metrics from a node in the execution plan.\n",
    "        These metrics are cost estimates calculated by the PostgreSQL planner.\n",
    "\n",
    "        See 'JSON Format Explain Plan' section in:\n",
    "        https://www.postgresonline.com/journal/archives/171-Explain-Plans-PostgreSQL-9.0-Text,-JSON,-XML,-YAML-Part-1-You-Choose.html\n",
    "\n",
    "        Parameters:\n",
    "        node (dict): Node of the execution plan.\n",
    "\n",
    "        Returns:\n",
    "        dict: Extracted cost metrics.\n",
    "        \"\"\"\n",
    "        props = {\n",
    "            'Node Type': node.get('Node Type'),\n",
    "            'Startup Cost': node.get('Startup Cost', 0.0),\n",
    "            'Total Cost': node.get('Total Cost', 0.0),\n",
    "            'Plan Rows': node.get('Plan Rows', 0),\n",
    "            'Plan Width': node.get('Plan Width', 0),\n",
    "            'Actual Startup Time': node.get('Actual Startup Time', 0.0),  # might not be useful for us\n",
    "            'Actual Total Time': node.get('Actual Total Time', 0.0),  # might not be useful for us\n",
    "            'Actual Rows': node.get('Actual Rows', 0),\n",
    "            'Actual Loops': node.get('Actual Loops', 1),\n",
    "            'Shared Hit Blocks': node.get('Shared Hit Blocks', 0),  # needed for scan formula\n",
    "            'Shared Read Blocks': node.get('Shared Read Blocks', 0),\n",
    "            'Shared Dirtied Blocks': node.get('Shared Dirtied Blocks', 0),\n",
    "            'Shared Written Blocks': node.get('Shared Written Blocks', 0),\n",
    "        }\n",
    "\n",
    "        return props\n",
    "\n",
    "\n",
    "    # TODO: Function to explain the computation of various cost in the QEP, explaining differences if any\n",
    "\n",
    "    def generate_report(self, analysis_results):\n",
    "        \"\"\"\n",
    "        Generates a formatted JSON report from the analysis results.\n",
    "\n",
    "        Parameters:\n",
    "        analysis_results (dict): Analysis results of the execution plan.\n",
    "\n",
    "        Returns:\n",
    "        str: A string representation of the JSON-formatted analysis report.\n",
    "        \"\"\"\n",
    "        report = json.dumps(analysis_results, indent=4)\n",
    "        logging.info(\"Report generated.\")\n",
    "        return report\n",
    "        \n",
    "class CostEstimator:\n",
    "    def __init__(self, properties):\n",
    "        self.properties = properties\n",
    "\n",
    "    def scan_cost_function(self, node) -> float:\n",
    "        rows, table_props = node['Plan Rows'], self.properties[node['Relation Name']]\n",
    "        seq_pages_accessed = table_props['pages']\n",
    "        print('test', seq_pages_accessed, rows)\n",
    "        explanation = f\"Cost function: (seq_pages_accessed * {self.properties['seq_page_cost']}) + (rows * {self.properties['cpu_tuple_cost']})\\nwhere seq_pages_accessed= {seq_pages_accessed} and rows= {rows}\"\n",
    "        return [(seq_pages_accessed * self.properties['seq_page_cost']) + (rows * self.properties['cpu_tuple_cost']), explanation]\n",
    "\n",
    "    def estimate(self, node):\n",
    "        operator = node['Node Type']\n",
    "        if operator == 'Seq Scan':\n",
    "            return self.scan_cost_function(node)\n",
    "        else:\n",
    "            raise Exception(f\"Cost function is undefined for operator {operator}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No rows fetched; Returning []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 4128 200000\n",
      "{\n",
      "    \"Node Type\": \"Seq Scan\",\n",
      "    \"Relation Name\": \"part\",\n",
      "    \"Cost Analysis\": {\n",
      "        \"Actual Estimated Cost\": 6128.0,\n",
      "        \"Estimated Cost\": 6128.0,\n",
      "        \"Explanation\": \"Cost function: (seq_pages_accessed * 1.0) + (rows * 0.01)\\nwhere seq_pages_accessed= 4128 and rows= 200000\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  SELECTION\n",
    "\"\"\"\n",
    "explainer = Explainer(conn)\n",
    "\n",
    "SELECT_PART_QUERY=\"\"\"\n",
    "SELECT p_partkey, p_name, p_mfgr, p_brand, p_type, p_size, p_container, p_retailprice, p_comment\n",
    "FROM public.part;\n",
    "\"\"\"\n",
    "out = explainer.run_explain(SELECT_PART_QUERY)\n",
    "result = explainer.analyze_execution_plan(out)\n",
    "print(explainer.generate_report(result))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  PROJECTION\\n  - No need to test projection of non PK columns as it will be sequential scan(covered in SELECTION)\\n  - Projection of primary key is quite complicated as it uses index-only scan.\\n    - Index only scan doesn't have a simple formula\\n      - Can derive from codebase\\n      - Instead we use this source https://postgrespro.com/blog/pgsql/5969493\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "  PROJECTION\n",
    "  - No need to test projection of non PK columns as it will be sequential scan(covered in SELECTION)\n",
    "  - Projection of primary key is quite complicated as it uses index-only scan.\n",
    "    - Index only scan doesn't have a simple formula\n",
    "      - Can derive from codebase\n",
    "      - Instead we use this source https://postgrespro.com/blog/pgsql/5969493\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
